import os
import re
from .ai_engine import HybridAIEngine

class FileAnalyzer:
    def __init__(self):
        # Initialize AI engine
        self.ai_engine = HybridAIEngine()
        
        # Tehlikeli dosya uzantÄ±larÄ±
        self.dangerous_extensions = [
            '.exe', '.scr', '.bat', '.cmd', '.com', '.pif', '.vbs', '.vbe',
            '.js', '.jar', '.ws', '.wsf', '.wsc', '.wsh', '.ps1', '.ps1xml',
            '.ps2', '.ps2xml', '.psc1', '.psc2', '.msh', '.msh1', '.msh2',
            '.mshxml', '.msh1xml', '.msh2xml', '.scf', '.lnk', '.inf',
            '.reg', '.app', '.deb', '.pkg', '.dmg', '.iso', '.img', '.bin',
            '.cue', '.mdf', '.toast', '.vcd', '.crx'
        ]
        
        # ÅžÃ¼pheli uzantÄ±lar (orta risk)
        self.suspicious_extensions = [
            '.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.xz', '.cab',
            '.msi', '.deb', '.rpm', '.apk', '.ipa', '.docm', '.xlsm',
            '.pptm', '.dotm', '.xltm', '.potm', '.ppam', '.xlam', '.docx',
            '.xlsx', '.pptx', '.pdf', '.rtf', '.swf', '.fla'
        ]
        
        # GÃ¼venli uzantÄ±lar
        self.safe_extensions = [
            '.txt', '.doc', '.xls', '.ppt', '.jpg', '.jpeg', '.png', '.gif',
            '.bmp', '.mp3', '.mp4', '.avi', '.mov', '.wav', '.ogg', '.flac',
            '.css', '.html', '.htm', '.xml', '.json', '.csv', '.log'
        ]
        
        # ÅžÃ¼pheli kelimeler
        self.suspicious_keywords = [
            'crack', 'keygen', 'patch', 'serial', 'license', 'activator',
            'hack', 'cheat', 'trojan', 'virus', 'malware', 'backdoor',
            'keylogger', 'spyware', 'ransomware', 'worm', 'rootkit',
            'invoice', 'receipt', 'payment', 'refund', 'statement',
            'urgent', 'important', 'confidential', 'secure', 'update',
            'installer', 'setup', 'download', 'free', 'premium'
        ]
        
        # ÅžÃ¼pheli dosya adÄ± kalÄ±plarÄ±
        self.suspicious_patterns = [
            r'.*crack.*',
            r'.*keygen.*',
            r'.*patch.*',
            r'.*serial.*',
            r'.*invoice.*\.(exe|scr|bat)',
            r'.*receipt.*\.(exe|scr|bat)',
            r'.*photo.*\.(exe|scr|bat)',
            r'.*video.*\.(exe|scr|bat)',
            r'.*document.*\.(exe|scr|bat)',
            r'.*\.(jpg|png|pdf|doc)\.exe',
            r'.*setup.*\.(exe|msi)',
            r'.*install.*\.(exe|msi)',
            r'.*update.*\.(exe|bat|scr)'
        ]

    def analyze(self, filename, file_content=""):
        """Enhanced file analysis with AI integration"""
        try:
            if not filename or len(filename.strip()) < 1:
                return {
                    'risk_score': 0.0,
                    'risk_level': 'GeÃ§ersiz Dosya',
                    'color': 'gray',
                    'warnings': ['GeÃ§ersiz dosya adÄ±'],
                    'details': {},
                    'recommendations': ['GeÃ§erli bir dosya adÄ± girin'],
                    'analysis_method': 'error'
                }
            
            filename = filename.strip()
            risk_score = 0
            warnings = []
            details = {}
            
            # 1. BASIC FILE ANALYSIS
            basic_score, basic_warnings, basic_details = self._basic_file_analysis(filename)
            risk_score += basic_score
            warnings.extend(basic_warnings)
            details.update(basic_details)
            
            # 2. ENHANCED RULE-BASED ANALYSIS
            rule_score, rule_warnings = self._enhanced_rule_analysis(filename, file_content)
            risk_score += rule_score
            warnings.extend(rule_warnings)
            
            # 3. AI-POWERED ANALYSIS
            ai_results = self.ai_engine.analyze_file_with_ai(filename, file_content)
            ai_score = ai_results['ai_score']
            warnings.extend(ai_results['ai_warnings'])
            details['ai_confidence'] = ai_results['confidence']
            details['malware_probability'] = ai_results['malware_probability']
            
            # 4. HYBRID SCORING
            final_score = self._calculate_hybrid_score(risk_score, ai_score, ai_results)
            
            # 5. DETERMINE RISK LEVEL
            risk_level, color = self._determine_risk_level(final_score)
            
            return {
                'risk_score': round(min(final_score, 100), 1),
                'risk_level': risk_level,
                'color': color,
                'warnings': warnings,
                'details': details,
                'recommendations': self._get_enhanced_recommendations(final_score, ai_results),
                'analysis_method': 'hybrid_ai' if self.ai_engine.ai_available else 'enhanced_rules'
            }
            
        except Exception as e:
            return {
                'risk_score': 50.0,
                'risk_level': 'Analiz HatasÄ±',
                'color': 'gray',
                'warnings': [f'Dosya analizi sÄ±rasÄ±nda hata: {str(e)}'],
                'details': {},
                'recommendations': ['Dosya adÄ±nÄ± kontrol edip tekrar deneyin'],
                'analysis_method': 'error'
            }

    def _get_file_extension(self, filename):
        """Dosya uzantÄ±sÄ±nÄ± al"""
        if '.' in filename:
            return '.' + filename.split('.')[-1].lower()
        return ''

    def _analyze_extension(self, extension):
        """Dosya uzantÄ±sÄ±nÄ± analiz et"""
        score = 0
        warnings = []
        
        if not extension:
            score += 10
            warnings.append('Dosya uzantÄ±sÄ± yok')
        elif extension in self.dangerous_extensions:
            score += 50
            warnings.append(f'Tehlikeli dosya uzantÄ±sÄ±: {extension}')
        elif extension in self.suspicious_extensions:
            score += 20
            warnings.append(f'ÅžÃ¼pheli dosya uzantÄ±sÄ±: {extension}')
        elif extension in self.safe_extensions:
            score += 0  # GÃ¼venli uzantÄ±
        else:
            score += 15
            warnings.append(f'Bilinmeyen dosya uzantÄ±sÄ±: {extension}')
        
        return score, warnings

    def _analyze_filename(self, filename):
        """Dosya adÄ± yapÄ±sÄ±nÄ± analiz et"""
        score = 0
        warnings = []
        
        # Dosya adÄ± uzunluÄŸu
        if len(filename) > 100:
            score += 15
            warnings.append('Ã‡ok uzun dosya adÄ±')
        
        # Ã‡ok kÄ±sa dosya adÄ±
        if len(filename) < 3:
            score += 20
            warnings.append('Ã‡ok kÄ±sa dosya adÄ±')
        
        # Ã‡ift uzantÄ± kontrolÃ¼
        parts = filename.split('.')
        if len(parts) > 2:
            # Ä°kinci uzantÄ± tehlikeli mi?
            if len(parts) >= 3:
                second_ext = '.' + parts[-2].lower()
                if second_ext in self.dangerous_extensions:
                    score += 40
                    warnings.append('Gizli tehlikeli uzantÄ± tespit edildi')
        
        # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf karÄ±ÅŸÄ±mÄ±
        if filename != filename.lower() and filename != filename.upper():
            # Normal durum, skor ekleme
            pass
        elif filename.isupper():
            score += 10
            warnings.append('TamamÄ± bÃ¼yÃ¼k harf')
        
        return score, warnings

    def _check_suspicious_keywords(self, filename):
        """ÅžÃ¼pheli kelime kontrolÃ¼"""
        score = 0
        warnings = []
        filename_lower = filename.lower()
        
        found_keywords = []
        for keyword in self.suspicious_keywords:
            if keyword in filename_lower:
                found_keywords.append(keyword)
        
        if found_keywords:
            score += len(found_keywords) * 10
            warnings.append(f'ÅžÃ¼pheli kelimeler: {", ".join(found_keywords[:5])}')
        
        return score, warnings

    def _check_suspicious_patterns(self, filename):
        """ÅžÃ¼pheli dosya adÄ± kalÄ±plarÄ±nÄ± kontrol et"""
        score = 0
        warnings = []
        filename_lower = filename.lower()
        
        for pattern in self.suspicious_patterns:
            if re.match(pattern, filename_lower):
                score += 30
                warnings.append('ÅžÃ¼pheli dosya adÄ± kalÄ±bÄ± tespit edildi')
                break
        
        return score, warnings

    def _analyze_characters(self, filename):
        """Karakter analizi"""
        score = 0
        warnings = []
        
        # Unicode karakterler
        if not filename.isascii():
            score += 15
            warnings.append('ASCII olmayan karakterler iÃ§eriyor')
        
        # Ã–zel karakterler
        special_chars = ['@', '#', '$', '%', '^', '&', '*', '(', ')', '+', '=']
        special_count = sum(filename.count(char) for char in special_chars)
        if special_count > 2:
            score += 10
            warnings.append('Ã‡ok fazla Ã¶zel karakter')
        
        # SayÄ± oranÄ±
        digit_count = sum(c.isdigit() for c in filename)
        if digit_count > len(filename) * 0.5:
            score += 15
            warnings.append('Ã‡ok fazla sayÄ± iÃ§eriyor')
        
        # BoÅŸluk karakterleri
        if '  ' in filename:  # Ã‡ift boÅŸluk
            score += 10
            warnings.append('Anormal boÅŸluk kullanÄ±mÄ±')
        
        return score, warnings

    def _get_recommendations(self, risk_score, extension):
        """Risk skoruna gÃ¶re tavsiyeler"""
        recommendations = []
        
        if risk_score >= 80:
            recommendations.extend([
                'Bu dosyayÄ± kesinlikle aÃ§mayÄ±n!',
                'DosyayÄ± hemen silin',
                'AntivirÃ¼s taramasÄ± yapÄ±n',
                'Sistem gÃ¼venliÄŸinizi kontrol edin'
            ])
        elif risk_score >= 60:
            recommendations.extend([
                'Bu dosya Ã§ok riskli gÃ¶rÃ¼nÃ¼yor',
                'AÃ§madan Ã¶nce antivirÃ¼s taramasÄ± yapÄ±n',
                'KaynaÄŸÄ±nÄ± doÄŸrulayÄ±n',
                'GÃ¼venilir kaynaklardan dosya indirin'
            ])
        elif risk_score >= 40:
            recommendations.extend([
                'Bu dosya ÅŸÃ¼pheli gÃ¶rÃ¼nÃ¼yor',
                'AntivirÃ¼s ile tarayÄ±n',
                'KaynaÄŸÄ±nÄ± kontrol edin',
                'Dikkatli olun'
            ])
        elif risk_score >= 20:
            recommendations.extend([
                'Dosya nispeten gÃ¼venli gÃ¶rÃ¼nÃ¼yor',
                'Yine de dikkatli olun',
                'Bilinmeyen kaynaklardan dosya aÃ§mayÄ±n'
            ])
        else:
            recommendations.extend([
                'Dosya gÃ¼venli gÃ¶rÃ¼nÃ¼yor',
                'Standart gÃ¼venlik Ã¶nlemlerini almayÄ± unutmayÄ±n'
            ])
        
        # UzantÄ±ya Ã¶zel tavsiyeler
        if extension in self.dangerous_extensions:
            recommendations.append(f'{extension} dosyalarÄ± potansiyel olarak tehlikelidir')
        
        return recommendations

    def _basic_file_analysis(self, filename):
        """Enhanced basic file analysis"""
        score = 0
        warnings = []
        details = {}
        
        # Dosya uzantÄ±sÄ±nÄ± al
        file_extension = self._get_file_extension(filename)
        details['extension'] = file_extension
        details['filename'] = filename
        
        # UzantÄ± analizi
        ext_score, ext_warnings = self._analyze_extension(file_extension)
        score += ext_score
        warnings.extend(ext_warnings)
        
        # Dosya adÄ± analizi
        name_score, name_warnings = self._analyze_filename(filename)
        score += name_score
        warnings.extend(name_warnings)
        
        return score, warnings, details

    def _enhanced_rule_analysis(self, filename, file_content):
        """Enhanced rule-based analysis"""
        score = 0
        warnings = []
        
        # ÅžÃ¼pheli kelime kontrolÃ¼
        keyword_score, keyword_warnings = self._check_suspicious_keywords(filename)
        score += keyword_score
        warnings.extend(keyword_warnings)
        
        # ÅžÃ¼pheli kalÄ±p kontrolÃ¼
        pattern_score, pattern_warnings = self._check_suspicious_patterns(filename)
        score += pattern_score
        warnings.extend(pattern_warnings)
        
        # Dosya boyutu ve karakter analizi
        char_score, char_warnings = self._analyze_characters(filename)
        score += char_score
        warnings.extend(char_warnings)
        
        # Ä°Ã§erik analizi (eÄŸer varsa)
        if file_content:
            content_score, content_warnings = self._analyze_file_content(file_content)
            score += content_score
            warnings.extend(content_warnings)
        
        return score, warnings

    def _analyze_file_content(self, content):
        """Analyze file content for suspicious patterns"""
        score = 0
        warnings = []
        content_lower = content.lower()
        
        # Suspicious strings in content
        malware_strings = [
            'backdoor', 'trojan', 'virus', 'malware', 'keylogger',
            'crypter', 'stealer', 'ransomware', 'botnet', 'exploit',
            'shellcode', 'payload', 'injection', 'bypass', 'rootkit'
        ]
        
        found_strings = []
        for mal_str in malware_strings:
            if mal_str in content_lower:
                found_strings.append(mal_str)
        
        if found_strings:
            score += len(found_strings) * 15
            warnings.append(f'ÅžÃ¼pheli iÃ§erik tespit edildi: {", ".join(found_strings[:3])}')
        
        # Check for encoded content
        if any(char in content for char in ['\\x', '%u', 'eval(', 'exec(']):
            score += 20
            warnings.append('KodlanmÄ±ÅŸ veya gizlenmiÅŸ iÃ§erik tespit edildi')
        
        return score, warnings

    def _calculate_hybrid_score(self, rule_score, ai_score, ai_results):
        """Calculate hybrid score combining rules and AI"""
        if self.ai_engine.ai_available and ai_score > 0:
            # Weighted combination: Rules 50% + AI 50% for files
            hybrid_score = (rule_score * 0.5) + (ai_score * 0.5)
            
            # Boost for high malware probability
            malware_prob = ai_results.get('malware_probability', 0)
            if malware_prob > 80:
                hybrid_score = min(100, hybrid_score * 1.4)
            
            # Confidence adjustment
            confidence = ai_results.get('confidence', 0)
            if confidence > 90:
                return hybrid_score
            elif confidence < 50:
                # Lower confidence, rely more on rules
                return (rule_score * 0.7) + (ai_score * 0.3)
            
            return hybrid_score
        else:
            # Fallback to enhanced rule-based scoring
            return rule_score

    def _determine_risk_level(self, score):
        """Improved risk level determination for better user experience"""
        if score >= 90:
            return 'Ã‡ok Tehlikeli', 'red'
        elif score >= 70:
            return 'YÃ¼ksek Risk', 'red'
        elif score >= 50:
            return 'Orta Risk', 'orange'
        elif score >= 30:
            return 'DÃ¼ÅŸÃ¼k Risk', 'yellow'
        elif score >= 10:
            return 'Minimal Risk', 'green'
        else:
            return 'GÃ¼venli', 'green'

    def _get_enhanced_recommendations(self, risk_score, ai_results):
        """Enhanced recommendations based on hybrid analysis"""
        recommendations = []
        
        if risk_score >= 80:
            recommendations.extend([
                'ðŸš¨ Bu dosya Ã§ok tehlikeli!',
                'ðŸ—‘ï¸ DosyayÄ± derhal silin',
                'ðŸš« Kesinlikle aÃ§mayÄ±n veya Ã§alÄ±ÅŸtÄ±rmayÄ±n',
                'ðŸ›¡ï¸ Sistem taramasÄ± yapÄ±n',
                'ðŸ“§ GÃ¼venlik uzmanÄ±na bildirin'
            ])
        elif risk_score >= 60:
            recommendations.extend([
                'âš ï¸ Bu dosya yÃ¼ksek risk taÅŸÄ±yor',
                'ðŸ” AÃ§madan Ã¶nce detaylÄ± tarama yapÄ±n',
                'ðŸŒ KaynaÄŸÄ±nÄ± mutlaka doÄŸrulayÄ±n',
                'ðŸ’» Ä°zole ortamda test edin',
                'ðŸ“ž IT destek ekibine danÄ±ÅŸÄ±n'
            ])
        elif risk_score >= 40:
            recommendations.extend([
                'ðŸ” Bu dosyaya dikkatli yaklaÅŸÄ±n',
                'âœ… AntivirÃ¼s taramasÄ± yapÄ±n',
                'ðŸ”— KaynaÄŸÄ±nÄ± kontrol edin',
                'ðŸ“± GÃ¼venli modda aÃ§mayÄ± deneyin'
            ])
        elif risk_score >= 20:
            recommendations.extend([
                'ðŸ‘ï¸ Dosya nispeten gÃ¼venli gÃ¶rÃ¼nÃ¼yor',
                'ðŸ” Yine de dikkatli olun',
                'ðŸ›¡ï¸ DÃ¼zenli gÃ¼venlik taramasÄ± yapÄ±n'
            ])
        else:
            recommendations.extend([
                'âœ… Dosya gÃ¼venli gÃ¶rÃ¼nÃ¼yor',
                'ðŸ›¡ï¸ Standart gÃ¼venlik Ã¶nlemlerini almayÄ± unutmayÄ±n'
            ])
        
        # AI-specific recommendations
        if self.ai_engine.ai_available:
            malware_prob = ai_results.get('malware_probability', 0)
            if malware_prob > 80:
                recommendations.append('ðŸ¤– AI: YÃ¼ksek malware olasÄ±lÄ±ÄŸÄ± tespit edildi')
            
            confidence = ai_results.get('confidence', 0)
            if confidence > 90:
                recommendations.append('ðŸ¤– AI analizi yÃ¼ksek gÃ¼ven seviyesi gÃ¶steriyor')
        
        return recommendations 