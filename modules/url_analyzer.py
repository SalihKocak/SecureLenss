import re
import urllib.parse
import tldextract
import whois
from datetime import datetime
import ssl
import socket
import requests
from .ai_engine import HybridAIEngine
import logging

class URLAnalyzer:
    def __init__(self):
        # Initialize AI engine with model support
        self.ai_engine = HybridAIEngine()
        
        # Get AI engine status
        ai_status = self.ai_engine.get_status()
        self.model_available = ai_status['ai_available']
        self.analysis_mode = 'hybrid_ai' if self.model_available else 'enhanced_rules'
        
        # Enhanced suspicious keywords with weights
        self.suspicious_keywords = {
            # High risk keywords
            'high_risk': {
                'free': 15, 'win': 20, 'winner': 25, 'urgent': 20, 'click': 10, 
                'now': 15, 'limited': 18, 'offer': 12, 'bonus': 20, 'gift': 18,
                'prize': 25, 'lottery': 30, 'congratulations': 20, 'bitcoin': 25,
                'crypto': 20, 'investment': 15, 'earn': 12, 'money': 15, 'cash': 18
            },
            # Medium risk keywords  
            'medium_risk': {
                'secure': 8, 'verify': 12, 'update': 10, 'confirm': 10, 
                'suspend': 15, 'account': 8, 'login': 10, 'password': 12,
                'paypal': 15, 'amazon': 10, 'bank': 15, 'credit': 12
            },
            # Phishing patterns
            'phishing': {
                'phishing': 50, 'scam': 45, 'fake': 40, 'suspicious': 30,
                'malware': 50, 'virus': 45, 'trojan': 50
            }
        }
        
        # Enhanced suspicious TLDs with risk scores
        self.suspicious_tlds = {
            '.tk': 35, '.ml': 35, '.ga': 35, '.cf': 35, '.pw': 30,
            '.top': 25, '.click': 30, '.download': 40, '.loan': 45,
            '.work': 20, '.review': 25, '.science': 30, '.racing': 35
        }
        
        # Known phishing/suspicious domains
        self.phishing_domains = {
            'bit.ly': 20, 'tinyurl.com': 20, 'short.link': 25, 'ow.ly': 15,
            't.co': 10, 'goo.gl': 15, 'tiny.cc': 20, 'is.gd': 15,
            'buff.ly': 10, 'soo.gd': 25, 'clicky.me': 30
        }
        
        # Legitimate domains (whitelist) - Enhanced with Turkish sites
        self.legitimate_domains = {
            # International sites
            'google.com', 'microsoft.com', 'apple.com', 'amazon.com',
            'facebook.com', 'twitter.com', 'linkedin.com', 'github.com',
            'stackoverflow.com', 'wikipedia.org', 'youtube.com', 'instagram.com',
            'whatsapp.com', 'telegram.org', 'discord.com', 'netflix.com',
            'spotify.com', 'paypal.com', 'ebay.com', 'airbnb.com',
            
            # Turkish Banks and Financial
            'garanti.com.tr', 'akbank.com', 'isbank.com.tr', 'yapikredi.com.tr',
            'ziraat.com.tr', 'vakifbank.com.tr', 'halkbank.com.tr', 'denizbank.com',
            'finansbank.com.tr', 'ingbank.com.tr', 'teb.com.tr', 'odeabank.com',
            'qnbfinansbank.com', 'sekerbankasi.com.tr', 'sekerbank.com.tr',
            
            # Turkish E-commerce
            'trendyol.com', 'hepsiburada.com', 'n11.com', 'gittigidiyor.com',
            'sahibinden.com', 'arabam.com', 'emlakjet.com', 'ciceksepeti.com',
            'getir.com', 'yemeksepeti.com', 'ticimax.com', 'pazarama.com',
            
            # Turkish News and Media
            'hurriyet.com.tr', 'sabah.com.tr', 'milliyet.com.tr', 'sozcu.com.tr', 
            'haberturk.com', 'ntv.com.tr', 'cnnturk.com', 'aa.com.tr',
            'trt.net.tr', 'star.com.tr', 'posta.com.tr', 'takvim.com.tr',
            
            # Turkish Retail and Shopping
            'a101.com.tr', 'bim.com.tr', 'migros.com.tr', 'carrefoursa.com',
            'teknosa.com', 'vatan.com', 'mediamarkt.com.tr', 'gold.com.tr',
            'defacto.com.tr', 'lcwaikiki.com', 'koton.com', 'mango.com',
            'zara.com', 'boyner.com.tr', 'beymen.com', 'morhipo.com',
            
            # Turkish Government and Education
            'turkiye.gov.tr', 'e-devlet.gov.tr', 'resmigazete.gov.tr',
            'meb.gov.tr', 'saglik.gov.tr', 'nvi.gov.tr', 'sgk.gov.tr',
            'tuik.gov.tr', 'maliye.gov.tr', 'adalet.gov.tr', 'jandarma.gov.tr',
            'erzurum.edu.tr', 'boun.edu.tr', 'metu.edu.tr', 'itu.edu.tr',
            'ankara.edu.tr', 'gazi.edu.tr', 'hacettepe.edu.tr', 'ytu.edu.tr',
            
            # Turkish Telecom and Utilities
            'turkcell.com.tr', 'vodafone.com.tr', 'turk.net', 'superonline.net',
            'ttnet.com.tr', 'migrosnet.com.tr', 'koc.net', 'millenicom.com.tr'
        }
        
        # URL pattern analysis
        self.suspicious_patterns = [
            (r'[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}', 35, 'IP address instead of domain'),
            (r'[a-zA-Z0-9]+-[a-zA-Z0-9]+-[a-zA-Z0-9]+\.', 15, 'Multiple hyphens in domain'),
            (r'[0-9]{5,}', 20, 'Long number sequence'),
            (r'[a-zA-Z]{1}[0-9]{3,}[a-zA-Z]{1}', 15, 'Mixed alphanumeric pattern'),
            (r'www\d+\.', 25, 'Numbered subdomain'),
            (r'[a-zA-Z0-9]{20,}', 18, 'Very long domain name'),
            (r'\.php\?.*=.*&.*=', 12, 'Complex PHP parameters'),
            (r'[%][0-9a-fA-F]{2}', 10, 'URL encoding detected')
        ]

    def analyze(self, url):
        """Enhanced URL analysis with AI integration"""
        try:
            # URL'yi normalize et
            original_url = url
            if not url.startswith(('http://', 'https://')):
                url = 'http://' + url
            
            try:
                parsed_url = urllib.parse.urlparse(url)
                domain = parsed_url.netloc.lower()
                if not domain:
                    raise ValueError("Ge√ßersiz URL formatƒ±: domain bulunamadƒ±")
            except Exception as e:
                raise ValueError(f"URL ayrƒ±≈ütƒ±rma hatasƒ±: {str(e)}")
            
            risk_score = 0
            warnings = []
            details = {}
            
            # 1. BASIC CHECKS
            try:
                basic_score, basic_warnings, basic_details = self._basic_analysis(url, domain)
                risk_score += basic_score
                warnings.extend(basic_warnings)
                details.update(basic_details)
            except Exception as e:
                logging.error(f"Basic analysis error: {e}")
                warnings.append("Temel analiz hatasƒ±")
                risk_score += 50  # Default risk for analysis failure
            
            # 2. ENHANCED RULE-BASED ANALYSIS
            try:
                rule_score, rule_warnings = self._enhanced_rule_analysis(url, domain)
                risk_score += rule_score
                warnings.extend(rule_warnings)
            except Exception as e:
                logging.error(f"Rule-based analysis error: {e}")
                warnings.append("Kural tabanlƒ± analiz hatasƒ±")
                risk_score += 30  # Default risk for rule analysis failure
            
            # 3. AI-POWERED ANALYSIS - Varsayƒ±lan deƒüerler ayarla
            ai_results = {
                'ai_score': 50,
                'confidence': 30,
                'ai_warnings': ['AI analizi kullanƒ±lamƒ±yor'],
                'api_checks': {}
            }
            ai_score = 50  # Varsayƒ±lan AI skoru
            
            try:
                ai_results = self.ai_engine.analyze_url_with_ai(url)
                ai_score = ai_results.get('ai_score', 50)
                warnings.extend(ai_results.get('ai_warnings', []))
                details['ai_confidence'] = ai_results.get('confidence', 30)
                details['api_checks'] = ai_results.get('api_checks', {})
                logging.info(f"AI analysis successful: score={ai_score}")
            except Exception as e:
                logging.error(f"AI analysis error: {e}")
                warnings.append("AI analizi hatasƒ±")
                details['ai_confidence'] = 30
                details['api_checks'] = {}
            
            # 4. HYBRID SCORING - Eƒüitilmi≈ü model ile optimal aƒüƒ±rlƒ±klar
            if self.model_available and ai_score > 0:
                # Eƒüitilmi≈ü ML model mevcut - dengeli aƒüƒ±rlƒ±k kullan
                final_score = (risk_score * 0.4) + (ai_score * 0.6)
                
                # Whitelist kontrol√º - g√ºvenilir siteler i√ßin ML'i sƒ±nƒ±rla
                if details.get('whitelisted', False):
                    final_score = min(final_score, 15)  # G√ºvenilir siteler max 15 puan
            else:
                # Sadece rule-based scoring kullan
                final_score = risk_score
            
            # Skorun ge√ßerli olduƒüundan emin ol
            if final_score is None or final_score < 0:
                final_score = 50.0
                warnings.append("Risk skoru hesaplanamadƒ±, varsayƒ±lan deƒüer atandƒ±")
            
            # 5. DETERMINE RISK LEVEL
            try:
                risk_level, color = self._determine_risk_level(final_score)
            except Exception as e:
                logging.error(f"Risk level determination error: {e}")
                risk_level = "Orta Risk"
                color = "orange"
            
            # AI g√ºven analizi hesapla
            try:
                ai_confidence = self._calculate_ai_confidence(final_score, ai_results, details)
            except Exception as e:
                logging.error(f"AI confidence calculation error: {e}")
                ai_confidence = {
                    'score': 50,
                    'level': 'Orta',
                    'color': '#FFD700',
                    'description': 'G√ºven seviyesi hesaplanamadƒ±'
                }
            
            # Final validations
            final_result = {
                'risk_score': round(min(max(final_score, 0), 100), 1),
                'risk_level': risk_level or 'Orta Risk',
                'color': color or 'orange',
                'warnings': warnings or ['Analiz tamamlandƒ±'],
                'details': details or {},
                'ai_confidence': ai_confidence,
                'recommendations': self._get_enhanced_recommendations(final_score, ai_results),
                'analysis_method': self.analysis_mode
            }
            
            # Log final result
            logging.info(f"URL Analysis completed: score={final_result['risk_score']}, level={final_result['risk_level']}")
            
            return final_result
            
        except Exception as e:
            logging.exception(f"URL analysis failed: {e}")
            return {
                'risk_score': 50.0,
                'risk_level': 'Analiz Hatasƒ±',
                'color': 'gray',
                'warnings': [f'Analiz hatasƒ±: {str(e)}'],
                'details': {'error': str(e)},
                'recommendations': ['URL formatƒ±nƒ± kontrol edin', 'Ge√ßerli bir URL girdiƒüinizden emin olun'],
                'analysis_method': 'error'
            }

    def _basic_analysis(self, url, domain):
        """Enhanced basic analysis"""
        score = 0
        warnings = []
        details = {}
        
        # Domain whitelist kontrol√º (daha kesin e≈üle≈üme)
        is_whitelisted = False
        for legit_domain in self.legitimate_domains:
            if domain == legit_domain or domain.endswith('.' + legit_domain):
                is_whitelisted = True
                break
        
        details['whitelisted'] = is_whitelisted
        
        if is_whitelisted:
            # G√ºvenilir siteler i√ßin √ßok d√º≈ü√ºk ba≈ülangƒ±√ß skoru
            score = 2  # G√ºvenilir siteler i√ßin √ßok d√º≈ü√ºk skor
            details['whitelist_bonus'] = True
            warnings.append('‚úÖ G√ºvenilir domain tespit edildi')
        else:
            details['whitelist_bonus'] = False
            # G√ºvenilir olmayan siteler i√ßin ba≈ülangƒ±√ß skoru
            score = 30  # Bilinmeyen siteler i√ßin ba≈ülangƒ±√ß riski
        
        # HTTPS kontrol√º
        if not url.startswith('https://'):
            if is_whitelisted:
                score += 10  # Reduced penalty for whitelisted sites
                warnings.append('HTTPS kullanmƒ±yor ama g√ºvenilir site')
            else:
                score += 25  # Full penalty for unknown sites
                warnings.append('URL HTTPS kullanmƒ±yor - g√ºvenli deƒüil')
        details['https'] = url.startswith('https://')
        
        # URL uzunluƒüu analizi (whitelist i√ßin daha toleranslƒ±)
        if len(url) > 100:
            if is_whitelisted:
                score += 5  # Minimal penalty for whitelisted sites
            else:
                score += 15
                warnings.append('√áok uzun URL')
        elif len(url) > 200:
            if is_whitelisted:
                score += 10
            else:
                score += 25
                warnings.append('A≈üƒ±rƒ± uzun URL - ≈ü√ºpheli')
            
        details['url_length'] = len(url)
        
        return score, warnings, details

    def _enhanced_rule_analysis(self, url, domain):
        """Enhanced rule-based analysis"""
        score = 0
        warnings = []
        
        # Enhanced keyword analysis
        keyword_score, keyword_warnings = self._analyze_keywords_weighted(url)
        score += keyword_score
        warnings.extend(keyword_warnings)
        
        # Domain analysis
        domain_score, domain_warnings = self._analyze_domain_enhanced(domain)
        score += domain_score
        warnings.extend(domain_warnings)
        
        # Pattern analysis
        pattern_score, pattern_warnings = self._analyze_patterns(url)
        score += pattern_score
        warnings.extend(pattern_warnings)
        
        # Subdomain analysis
        subdomain_score, subdomain_warnings = self._analyze_subdomains(domain)
        score += subdomain_score
        warnings.extend(subdomain_warnings)
        
        return score, warnings

    def _analyze_keywords_weighted(self, url):
        """Weighted keyword analysis"""
        score = 0
        warnings = []
        url_lower = url.lower()
        found_keywords = []
        
        # Check high risk keywords
        for keyword, weight in self.suspicious_keywords['high_risk'].items():
            if keyword in url_lower:
                score += weight
                found_keywords.append(f"{keyword}({weight})")
        
        # Check medium risk keywords
        for keyword, weight in self.suspicious_keywords['medium_risk'].items():
            if keyword in url_lower:
                score += weight
                found_keywords.append(f"{keyword}({weight})")
        
        # Check phishing keywords
        for keyword, weight in self.suspicious_keywords['phishing'].items():
            if keyword in url_lower:
                score += weight
                found_keywords.append(f"{keyword}({weight})")
        
        if found_keywords:
            warnings.append(f'≈û√ºpheli kelimeler: {", ".join(found_keywords[:5])}')
        
        return score, warnings

    def _analyze_domain_enhanced(self, domain):
        """Enhanced domain analysis"""
        score = 0
        warnings = []
        
        try:
            extracted = tldextract.extract(domain)
            tld = '.' + extracted.suffix
            subdomain = extracted.subdomain
            main_domain = extracted.domain
            
            # TLD analysis with weights
            if tld in self.suspicious_tlds:
                tld_score = self.suspicious_tlds[tld]
                score += tld_score
                warnings.append(f'≈û√ºpheli domain uzantƒ±sƒ±: {tld} (+{tld_score})')
            
            # Phishing domain check
            full_domain = f"{main_domain}{tld}"
            if full_domain in self.phishing_domains:
                phish_score = self.phishing_domains[full_domain]
                score += phish_score
                warnings.append(f'Bilinen ≈ü√ºpheli domain: {full_domain} (+{phish_score})')
            
            # Domain age analysis (improved)
            try:
                domain_info = whois.whois(full_domain)
                if domain_info.creation_date:
                    if isinstance(domain_info.creation_date, list):
                        creation_date = domain_info.creation_date[0]
                    else:
                        creation_date = domain_info.creation_date
                    
                    domain_age = (datetime.now() - creation_date).days
                    
                    if domain_age < 7:
                        score += 40
                        warnings.append('√áok yeni domain (1 haftadan az)')
                    elif domain_age < 30:
                        score += 25
                        warnings.append('Yeni domain (30 g√ºnden az)')
                    elif domain_age < 90:
                        score += 10
                        warnings.append('Nispeten yeni domain (90 g√ºnden az)')
            except Exception as domain_age_error:
                logging.warning(f"Domain age check failed: {domain_age_error}")
                score += 15
                warnings.append('Domain ya≈üƒ± bilgisi alƒ±namadƒ±')
            
        except Exception as e:
            score += 20
            warnings.append(f'Domain analiz hatasƒ±: {str(e)}')
        
        return score, warnings

    def _analyze_patterns(self, url):
        """URL pattern analysis"""
        score = 0
        warnings = []
        
        for pattern, pattern_score, description in self.suspicious_patterns:
            if re.search(pattern, url):
                score += pattern_score
                warnings.append(f'{description} (+{pattern_score})')
        
        return score, warnings

    def _analyze_subdomains(self, domain):
        """Advanced subdomain analysis"""
        score = 0
        warnings = []
        
        subdomain_count = domain.count('.')
        if subdomain_count > 3:
            score += 20
            warnings.append(f'√áok fazla subdomain ({subdomain_count})')
        elif subdomain_count > 5:
            score += 35
            warnings.append(f'A≈üƒ±rƒ± subdomain sayƒ±sƒ± ({subdomain_count})')
        
        # Check for suspicious subdomain patterns
        suspicious_subdomains = [
            'secure', 'login', 'verify', 'account', 'update',
            'confirm', 'support', 'service', 'admin'
        ]
        
        for sus_sub in suspicious_subdomains:
            if sus_sub in domain:
                score += 12
                warnings.append(f'≈û√ºpheli subdomain: {sus_sub}')
                break
        
        return score, warnings

    def _calculate_hybrid_score(self, rule_score, ai_score):
        """Calculate hybrid score with intelligent weighting"""
        if not self.ai_engine.ai_available or ai_score == 0:
            return rule_score
        
        # Check if this is a whitelisted domain
        # We need to pass domain info somehow - let's modify this
        
        # Standard hybrid calculation: Rules 40% + AI 40% + APIs 20%
        hybrid_score = (rule_score * 0.4) + (ai_score * 0.4)
        
        # If rule score is very low (indicating whitelist), reduce AI influence
        if rule_score < 10:  # Strong indication of whitelisted domain
            # For whitelisted sites, trust rules more than AI
            hybrid_score = (rule_score * 0.8) + (ai_score * 0.2)
            # Cap the maximum score for whitelisted sites
            hybrid_score = min(hybrid_score, 25)
        
        return max(0, hybrid_score)

    def _calculate_ai_confidence(self, final_score, ai_results, details):
        """AI g√ºven seviyesini hesapla"""
        confidence_factors = {
            'base_confidence': 50,  # Ba≈ülangƒ±√ß g√ºveni
            'model_bonus': 0,
            'whitelist_bonus': 0,
            'consistency_bonus': 0,
            'data_quality_bonus': 0
        }
        
        # Model kullanƒ±labilirliƒüi bonusu
        if self.model_available:
            confidence_factors['model_bonus'] = 25
        
        # Whitelist bonusu
        if details.get('whitelisted', False):
            confidence_factors['whitelist_bonus'] = 20
        
        # Rule-based ve AI tutarlƒ±lƒ±ƒüƒ±
        if ai_results and 'ai_score' in ai_results:
            rule_score = final_score - (ai_results['ai_score'] * 0.6)  # Yakla≈üƒ±k rule score
            score_diff = abs(rule_score - ai_results['ai_score'])
            
            if score_diff < 10:  # √áok tutarlƒ±
                confidence_factors['consistency_bonus'] = 15
            elif score_diff < 20:  # Tutarlƒ±
                confidence_factors['consistency_bonus'] = 10
            elif score_diff < 30:  # Kƒ±smen tutarlƒ±
                confidence_factors['consistency_bonus'] = 5
        
        # Veri kalitesi bonusu
        if details.get('https', False):
            confidence_factors['data_quality_bonus'] += 5
        if len(details.get('warnings', [])) < 3:  # Az uyarƒ± = daha net sonu√ß
            confidence_factors['data_quality_bonus'] += 5
        
        # Toplam g√ºven seviyesi
        total_confidence = sum(confidence_factors.values())
        
        # 0-100 arasƒ±nda normalize et
        normalized_confidence = min(100, max(20, total_confidence))
        
        # G√ºven seviyesi kategorisi
        if normalized_confidence >= 90:
            confidence_level = "√áok Y√ºksek"
            confidence_color = "#006400"  # Dark green
        elif normalized_confidence >= 75:
            confidence_level = "Y√ºksek"
            confidence_color = "#32CD32"  # Lime green
        elif normalized_confidence >= 60:
            confidence_level = "Orta"
            confidence_color = "#FFD700"  # Gold
        elif normalized_confidence >= 45:
            confidence_level = "D√º≈ü√ºk"
            confidence_color = "#FFA500"  # Orange
        else:
            confidence_level = "√áok D√º≈ü√ºk"
            confidence_color = "#DC143C"  # Crimson
        
        return {
            'score': round(normalized_confidence, 1),
            'level': confidence_level,
            'color': confidence_color,
            'factors': confidence_factors,
            'description': self._get_confidence_description(normalized_confidence)
        }

    def _get_confidence_description(self, confidence_score):
        """G√ºven seviyesi a√ßƒ±klamasƒ±"""
        if confidence_score >= 90:
            return "AI analizi son derece g√ºvenilir. Sonu√ßlara kesin olarak g√ºvenebilirsiniz."
        elif confidence_score >= 75:
            return "AI analizi g√ºvenilir. Sonu√ßlar y√ºksek doƒürulukta."
        elif confidence_score >= 60:
            return "AI analizi makul g√ºvenilirlikte. Ek doƒürulama √∂nerilir."
        elif confidence_score >= 45:
            return "AI analizi d√º≈ü√ºk g√ºvenilirlikte. Manuel doƒürulama gerekli."
        else:
            return "AI analizi √ßok d√º≈ü√ºk g√ºvenilirlikte. Sonu√ßlarƒ± dikkatli deƒüerlendirin."

    def _determine_risk_level(self, score):
        """Geli≈ümi≈ü risk seviyesi belirleme - Daha hassas eƒüri"""
        if score >= 85:
            return 'Kritik Tehlike', '#8B0000'  # Dark red
        elif score >= 70:
            return 'Y√ºksek Risk', '#DC143C'     # Crimson
        elif score >= 55:
            return 'Orta-Y√ºksek Risk', '#FF6347' # Tomato
        elif score >= 40:
            return 'Orta Risk', '#FF8C00'       # Dark orange
        elif score >= 25:
            return 'D√º≈ü√ºk-Orta Risk', '#FFA500' # Orange
        elif score >= 15:
            return 'D√º≈ü√ºk Risk', '#FFD700'      # Gold
        elif score >= 8:
            return 'Minimal Risk', '#9ACD32'    # Yellow green
        elif score >= 3:
            return 'G√ºvenli', '#32CD32'         # Lime green
        else:
            return '√áok G√ºvenli', '#006400'     # Dark green

    def _get_enhanced_recommendations(self, risk_score, ai_results):
        """Enhanced recommendations based on hybrid analysis"""
        recommendations = []
        
        if risk_score >= 80:
            recommendations.extend([
                'üö® Bu URL\'ye kesinlikle eri≈ümeyin!',
                '‚ö†Ô∏è Bilgisayarƒ±nƒ±zƒ± antivir√ºs ile tarayƒ±n',
                'üîí Ki≈üisel bilgilerinizi asla girmeyin',
                'üìß URL\'yi g√ºvenlik ekibinize bildirin'
            ])
        elif risk_score >= 60:
            recommendations.extend([
                '‚ö†Ô∏è Bu URL y√ºksek risk ta≈üƒ±yor',
                'üîç Kaynaƒüƒ±nƒ± mutlaka doƒürulayƒ±n',
                'üõ°Ô∏è VPN kullanarak eri≈ümeyi d√º≈ü√ºn√ºn',
                'üíª Sanal makine √ºzerinde test edin'
            ])
        elif risk_score >= 40:
            recommendations.extend([
                'üîç Bu URL\'ye dikkatli yakla≈üƒ±n',
                '‚úÖ Resmi kaynaklardan doƒürulayƒ±n',
                'üîí Ki≈üisel bilgi girmeden √∂nce iki kez d√º≈ü√ºn√ºn',
                'üì± Mobil cihazdan eri≈ümeyi tercih edin'
            ])
        elif risk_score >= 20:
            recommendations.extend([
                'üëÅÔ∏è URL nispeten g√ºvenli g√∂r√ºn√ºyor',
                'üîç Yine de dikkatli olun',
                'üåê HTTPS baƒülantƒ±sƒ±nƒ± tercih edin'
            ])
        else:
            recommendations.extend([
                '‚úÖ URL g√ºvenli g√∂r√ºn√ºyor',
                'üõ°Ô∏è Standart g√ºvenlik √∂nlemlerini almayƒ± unutmayƒ±n'
            ])
        
        # AI-specific recommendations
        if self.ai_engine.ai_available:
            if ai_results['confidence'] > 80:
                recommendations.append('ü§ñ AI analizi y√ºksek g√ºven seviyesi g√∂steriyor')
            
            api_checks = ai_results.get('api_checks', {})
            if any(score == 100 for score in api_checks.values() if isinstance(score, (int, float))):
                recommendations.append('‚ö†Ô∏è G√ºvenlik API\'leri tehdit tespit etti')
        
        return recommendations 